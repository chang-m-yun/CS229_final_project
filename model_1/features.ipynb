{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "l6TRBCsjVA9o"
      ],
      "authorship_tag": "ABX9TyNjYoOIcGz6th1XyUdwnhJz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Xiaowei0402/CS229_final_project/blob/main/CS229_new_feateng_consolidated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define dataset name and template type\n",
        "\n",
        "**Please fill in before running the code**"
      ],
      "metadata": {
        "id": "SYYQPAnKUvny"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEEehFYoPL3p"
      },
      "outputs": [],
      "source": [
        "dataname = 'GSM4705209_293T_mNG_rep1.csv'\n",
        "datatype = 'mNG'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running Feature engineering"
      ],
      "metadata": {
        "id": "b8rpwl6YU5qA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Some helper functions"
      ],
      "metadata": {
        "id": "l6TRBCsjVA9o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get reverse complement sequence\n",
        "def reverse_comp(seq):\n",
        "  seq = seq[::-1].upper()\n",
        "  rc_seq = []\n",
        "  for i in seq:\n",
        "    if i=='A':\n",
        "      rc_seq.append(\"T\")\n",
        "    elif i=='T':\n",
        "      rc_seq.append('A')\n",
        "    elif i=='C':\n",
        "      rc_seq.append('G')\n",
        "    else:\n",
        "      rc_seq.append('C')\n",
        "\n",
        "  return ''.join(rc_seq)"
      ],
      "metadata": {
        "id": "M-2ze3kAVF-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import dataset"
      ],
      "metadata": {
        "id": "Fx72YTMOU-5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import copy"
      ],
      "metadata": {
        "id": "RM07VGgcU-B0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLQdn-mmVRf-",
        "outputId": "120c2f57-126e-4d49-c832-bf50fd91b754"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "os.chdir('/content/drive/MyDrive/CS229_Final_Project/GSE155490_RAW')\n",
        "\n",
        "# Load information of target strand\n",
        "df_strand_info = pd.read_csv('target_strand_indicator.csv', header=[1])\n",
        "\n",
        "# load info of template strand\n",
        "template_B2 = reverse_comp(df_strand_info[df_strand_info.desc == 'perfect_ds'].seq.to_list()[0])\n",
        "template_mNG = reverse_comp(df_strand_info[df_strand_info.desc == 'mNG_perfect_ds'].seq.to_list()[0])\n",
        "\n",
        "template = {'B2': template_B2, 'mNG': template_mNG}\n",
        "\n",
        "# read the specific dataset\n",
        "df = pd.read_csv(dataname)"
      ],
      "metadata": {
        "id": "OPNGkP08VYCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract features"
      ],
      "metadata": {
        "id": "FHd6hS-LVn_w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mapping the oligo sequence and result by barcode"
      ],
      "metadata": {
        "id": "qRAesnHfaK54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this is tied to each result dataset\n",
        "def map_index(df, df_info):\n",
        "  map_dict = {}\n",
        "\n",
        "  for i in range(len(df)):\n",
        "    curr_bc = df.iloc[i].BC\n",
        "    info_ind = df_info.index[df_info['barcode'] == curr_bc].to_numpy()[0]\n",
        "    map_dict.update({i:info_ind})\n",
        "\n",
        "  return map_dict\n",
        "\n",
        "map_dict = map_index(df, df_strand_info)"
      ],
      "metadata": {
        "id": "euqHJwXTVqHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create features"
      ],
      "metadata": {
        "id": "3nGpcc0WaV4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_features():\n",
        "\n",
        "  # create a new dataframe to store the extracted features, for each A\n",
        "  # comp_seq_ind: the index of the sequence entry in the result dataset\n",
        "  # A_pos: position of the A that we are focusing on, position starting at #1\n",
        "  # distance_to_5: distance of this A to the 5' end of the dsRNA region\n",
        "  # distance_to_3: distance of this A to the 3' end of the dsRNA region\n",
        "  # global_GC_content: global GC content of this complementary strand\n",
        "  # local_GC_content_21: the GC content calculated from a local 21-bp region (10bp upstream + 10bp downstream), based on domain knowledge\n",
        "  # 'bulge-T/TTC/TTCTT/TTCTTCT': if the complementary strand belongs to the case of the bulge\n",
        "  # bulgesite: 1 / where is the bulge as centered to this A\n",
        "  # mismatch_site_num: how many mismatched sites (could be one mismatched site with multiple mismatches)\n",
        "  # mismatch_num: how many bases are mismatched for each mismatch site\n",
        "  # mismatch_site_1/2: 1 / where the mismatch is as centered to this A (1 is the one closer to 5' end and 2 closer to 3' end)\n",
        "  # G_penality_1/2: calculated gibbs free energy penalty induced by each mutation site\n",
        "  # editing_site_mismatch: if this A is mismatched\n",
        "  # is_toC: if this editing site mismatch is a A:C mismatch\n",
        "  # is_toG: if this editing site mismatch is a A:G mismatch\n",
        "  # is_out_of_ds: if this A is outside of dsRNA region\n",
        "  # y: percentage of editing efficiency of this A\n",
        "  # delta_y: changes in percentage of editing efficiency of this A compared to the perfectly double stranded starting sequence\n",
        "  features = ['comp_seq_ind', 'A_pos', 'distance_to_5', 'distance_to_3','global_GC_content','local_GC_content_21','bulge-T', 'bulge-TTC','bulge-TTCTT','bulge-TTCTTCT','bulgesite',\n",
        "              'mismatch_site_num', 'mismatch_num','mismatch_site_1','G_penalty_1','mismatch_site_2','G_penalty_2', 'editing_site_mismatch','is_toC','is_toG','is_out_of_ds','y','delta_y']\n",
        "\n",
        "  df_extracted_A = pd.DataFrame(columns = features)\n",
        "  return df_extracted_A, features"
      ],
      "metadata": {
        "id": "Ni-2s-otalhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper functions"
      ],
      "metadata": {
        "id": "tn8CmzNja1n1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# helper function: find where the mismatch is regarding the template strand\n",
        "# returning indicies of the mismatch on the template strand\n",
        "\n",
        "def find_mismatches(temp, comp):\n",
        "  RC_comp = reverse_comp(comp)\n",
        "  return [i for i in range(len(temp)) if temp[i] != RC_comp[i]]"
      ],
      "metadata": {
        "id": "97UFtvQnav8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# helper function: calculate free energy penalty at each mismatch site\n",
        "# free energy of each single base pair fetched from this paper: doi: 10.1261/rna.1734309\n",
        "# Real RNA structure and energies are much more sublte, this is just a crude estimate\n",
        "# Base pairing energies (kcal/mol): CG: -5.53; UA: -4.42; UG: -4.45; UU: -5.82; UC:-0.37; other base pair: 0\n",
        "# input: string of template sequence; and the reversed string of mismatch complementary sequence\n",
        "\n",
        "def calculate_G_penalty(temp,mis_rev):\n",
        "  # larger G_penalty indicates weaker binding\n",
        "  dict_pair_eng = {'C':-5.53,'G':-5.53, 'A':-4.42,'T':-4.42}\n",
        "  dict_mis_eng = {'G':-4.45,'T':-5.82,'C':-0.37}\n",
        "\n",
        "  G_penalty = 0\n",
        "\n",
        "  for i in range(len(temp)):\n",
        "    prev_energy = dict_pair_eng[temp[i]]\n",
        "    if temp[i] == 'T':\n",
        "      cur_energy = dict_mis_eng[mis_rev[i]]\n",
        "    elif mis_rev[i] == 'T':\n",
        "      cur_energy = dict_mis_eng[temp[i]]\n",
        "    else:\n",
        "      cur_energy = 0\n",
        "    G_penalty += cur_energy - prev_energy\n",
        "\n",
        "  return G_penalty"
      ],
      "metadata": {
        "id": "deHhjImfa9lX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# helper function: find out indicies of As on the template strand\n",
        "def find_A_inds(seq):\n",
        "   return [i for i in range(len(seq)) if seq.startswith('A', i)]"
      ],
      "metadata": {
        "id": "QPTN5MPta-B8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# helper function: calculate GC content of a given sequence\n",
        "\n",
        "def cal_GC_content(seq):\n",
        "  return (seq.count('G') + seq.count('G'))/len(seq)"
      ],
      "metadata": {
        "id": "1I05XeUBa-Gr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# helper functin: calculate mismatch distance\n",
        "# input mm_sites: only all the mutations in one site\n",
        "\n",
        "def cal_mm_dist(mm_site, A_site):\n",
        "  if mm_site[0] < A_site:\n",
        "    return mm_site[-1]-A_site\n",
        "  else:\n",
        "    return mm_site[0]-A_site"
      ],
      "metadata": {
        "id": "p-P4_yiTbBrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### loop through dataset"
      ],
      "metadata": {
        "id": "l_eZi_12bI_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_by_A(df, df_strand_info, temp_seq = template[datatype]):\n",
        "  df_extracted_A, features = create_features()\n",
        "  map_dict = map_index(df, df_strand_info)\n",
        "\n",
        "  A_num = temp_seq.count('A')\n",
        "  A_inds = find_A_inds(temp_seq)\n",
        "\n",
        "  # loop through each data point\n",
        "  for i in range (len(df)):\n",
        "    # define a flag for different types of the data point\n",
        "    # 0: to be discarded; 1: bulge; 2: mismatch; 3: disrupt or extend; 4: perfect_ds\n",
        "    typeflag = 0\n",
        "\n",
        "    # ignore control entries\n",
        "    if df_strand_info.iloc[map_dict[i]]['sample.ctrl'] == 'barcode_ctrl':\n",
        "      continue\n",
        "\n",
        "    curr_x = np.zeros([1,len(features)])[0]\n",
        "    comp_seq = df_strand_info.iloc[map_dict[i]].seq\n",
        "    comp_rev = comp_seq[::-1]\n",
        "\n",
        "    curr_x[0] = i\n",
        "    curr_x[4] = cal_GC_content(comp_seq)\n",
        "\n",
        "    comp_desc = df_strand_info.iloc[map_dict[i]].desc\n",
        "    comp_site_raw = df_strand_info.iloc[map_dict[i]].site\n",
        "\n",
        "    # in the case of bulge\n",
        "    if 'bulge' in comp_desc:\n",
        "      typeflag = 1\n",
        "      if comp_desc == 'bulge-T':\n",
        "        curr_x[6] = 1\n",
        "      elif comp_desc == 'bulge-TTC':\n",
        "        curr_x[7] = 1\n",
        "      elif comp_desc == 'bulge-TTCTT':\n",
        "        curr_x[8] = 1\n",
        "      elif comp_desc == 'bulge-TTCTTCT':\n",
        "        curr_x[9] = 1\n",
        "    else:\n",
        "      # nobulge\n",
        "      curr_x[10] = 0\n",
        "\n",
        "    # in the case of mismatches\n",
        "    if ('mismatch' in comp_desc) or ('Tto' in comp_desc):\n",
        "      typeflag = 2\n",
        "      if 'double' in comp_desc:\n",
        "        # double mutation\n",
        "        curr_x[11] = 2\n",
        "        # all individual sites of mismatches\n",
        "        # this will be useful later on\n",
        "        mismatched_sites = find_mismatches(temp_seq,comp_seq)\n",
        "        # number of mismatches\n",
        "        mm_len = int(len(mismatched_sites) /2)\n",
        "        curr_x[12] = mm_len\n",
        "        # calculate energy penalty for the first site:\n",
        "        curr_x[14] = calculate_G_penalty(temp_seq[mismatched_sites[0]:mismatched_sites[mm_len-1]+1],\n",
        "                                        comp_rev[mismatched_sites[0]:mismatched_sites[mm_len-1]+1])\n",
        "        # calculate energy penalty for the second site:\n",
        "        curr_x[16] = calculate_G_penalty(temp_seq[mismatched_sites[mm_len]:mismatched_sites[-1]+1],\n",
        "                                        comp_rev[mismatched_sites[mm_len]:mismatched_sites[-1]+1])\n",
        "      else:\n",
        "        # single mutation, including editing site specific change ('TtoC' or 'TtoG')\n",
        "        curr_x[11] = 1\n",
        "        curr_x[15] = 0\n",
        "        # all individual sites of mismatches\n",
        "        mismatched_sites = find_mismatches(temp_seq,comp_seq)\n",
        "        # number of mismatches\n",
        "        mm_len = int(len(mismatched_sites))\n",
        "        curr_x[12] = mm_len\n",
        "        # calculate energy penalty:\n",
        "        curr_x[14] = calculate_G_penalty(temp_seq[mismatched_sites[0]:mismatched_sites[mm_len-1]+1],\n",
        "                                        comp_rev[mismatched_sites[0]:mismatched_sites[mm_len-1]+1])\n",
        "    else:\n",
        "      # no mutation\n",
        "      curr_x[13] = 0\n",
        "      curr_x[15] = 0\n",
        "\n",
        "    # in the case of disrupted or extended complementary\n",
        "    complement_site_inds = [0, len(temp_seq)-1]\n",
        "    if 'disrupt' in comp_desc or 'extend' in comp_desc:\n",
        "      typeflag = 3\n",
        "      if comp_desc == 'disrupt_from_beginning':\n",
        "        complement_site_inds[0] = len(temp_seq)-1-int(comp_site_raw)\n",
        "      elif comp_desc == 'disrupt_from_bulge':\n",
        "        complement_site_inds[1] = len(temp_seq)-1-int(comp_site_raw)\n",
        "      elif 'extend_into_mNG' in comp_desc:\n",
        "        complement_site_inds[0] = - int(comp_desc[-2:])\n",
        "\n",
        "    # if it's a perfect ds:\n",
        "    if 'perfect' in comp_desc:\n",
        "      typeflag =4\n",
        "\n",
        "    # if it belongs to other category that we don't care about\n",
        "    # skip this result entry\n",
        "    if typeflag == 0:\n",
        "      continue\n",
        "\n",
        "    # Next, loop through each A\n",
        "    for Ai in A_inds:\n",
        "      # mostly what we need to do is to find out the distance of each modification to this A\n",
        "      # also need to compute local GC content\n",
        "      curr_Ai_x = copy.deepcopy(curr_x)\n",
        "      curr_Ai_x[1] = Ai\n",
        "\n",
        "      # Add y information\n",
        "      curr_Ai_x[-2] = df.iloc[i]['A'+str(A_inds.index(Ai)+1)]\n",
        "\n",
        "      # Add delta y\n",
        "      # fetch data for perfectly complementary strand\n",
        "      perfect_comp = df[df['desc'].str.contains(\"perfect\")]\n",
        "      perfect_edit = float(perfect_comp['A'+str(A_inds.index(Ai)+1)])\n",
        "      curr_Ai_x[-1] = df.iloc[i]['A'+str(A_inds.index(Ai)+1)] - perfect_edit\n",
        "\n",
        "      # compute local GC content\n",
        "      # get the closest 20 bp sequence on the complementary strand\n",
        "      slice_inds = [Ai-10, Ai+10]\n",
        "      if slice_inds[0] < 0:\n",
        "        slice_inds[1] = slice_inds[1] + abs(slice_inds[0])\n",
        "        slice_inds[0] = 0\n",
        "      elif slice_inds[1] > len(temp_seq)-1:\n",
        "        slice_inds[0] = slice_inds[0] - (slice_inds[1] - len(temp_seq) +1)\n",
        "        slice_inds[1] = len(temp_seq)-1\n",
        "\n",
        "      # calculate GC content\n",
        "      curr_Ai_x[5] = cal_GC_content(comp_rev[slice_inds[0]:slice_inds[1]+1])\n",
        "\n",
        "      # Calculate distance to the ends of dsRNA region\n",
        "      curr_Ai_x[2] = complement_site_inds[0] - Ai\n",
        "      curr_Ai_x[3] = complement_site_inds[1] - Ai\n",
        "      if curr_Ai_x[2] * curr_Ai_x[3] > 0:\n",
        "        # if this A is out of complementarity\n",
        "        curr_Ai_x[20] = 1\n",
        "\n",
        "      # calculate site information\n",
        "      if typeflag == 1:\n",
        "        # if it's a bulge\n",
        "        mi = int(comp_site_raw)\n",
        "        if mi == Ai:\n",
        "          curr_Ai_x[10] = 0\n",
        "          curr_Ai_x[20] = 1\n",
        "        else:\n",
        "          curr_Ai_x[10] = 1/(mi - Ai)\n",
        "      elif typeflag == 2:\n",
        "        # if mismatch\n",
        "        # first, if it's a editing site variant\n",
        "        mi = mismatched_sites\n",
        "        # if the mismatch happens on this A\n",
        "        if Ai in mi:\n",
        "          if ('Tto' in comp_desc) or curr_Ai_x[12] == 1:\n",
        "            # mutation site length is 1\n",
        "            curr_Ai_x[17] = 1\n",
        "            if comp_desc == 'TtoC' or comp_rev[Ai] == 'C':\n",
        "              curr_Ai_x[18] = 1\n",
        "            elif comp_desc == 'TtoG' or comp_rev[Ai] == 'G':\n",
        "              curr_Ai_x[19] = 1\n",
        "          else:\n",
        "            # longer mutation site length, treat this A as not in dsRNA\n",
        "            curr_Ai_x[20] = 1\n",
        "\n",
        "        # record the location of each mutation\n",
        "        if curr_Ai_x[11] == 1:\n",
        "          # single mutation:\n",
        "          if Ai not in mi:\n",
        "            curr_Ai_x[13] = 1/cal_mm_dist(mi, Ai)\n",
        "        elif curr_Ai_x[11] == 2:\n",
        "          # double mutation:\n",
        "          if Ai not in mi[:int(len(mi)/2)]:\n",
        "            curr_Ai_x[13] = 1/cal_mm_dist(mi[:int(len(mi)/2)], Ai)\n",
        "          if Ai not in mi[int(len(mi)/2):]:\n",
        "            curr_Ai_x[15] = 1/cal_mm_dist(mi[int(len(mi)/2):], Ai)\n",
        "\n",
        "      # Add rows to the dataframe\n",
        "      df_extracted_A.loc[len(df_extracted_A.index)] = curr_Ai_x\n",
        "\n",
        "  return df_extracted_A"
      ],
      "metadata": {
        "id": "3IJ2IqqqbRoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run on dataset"
      ],
      "metadata": {
        "id": "tPgElSN27Y_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_df = split_by_A(df, df_strand_info, temp_seq = template[datatype])\n",
        "os.chdir('/content/drive/MyDrive/CS229_Final_Project')\n",
        "result_df.to_csv('converted_new_'+dataname)"
      ],
      "metadata": {
        "id": "Brs7M0GV7c9D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
